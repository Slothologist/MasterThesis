@misc{JACK,
	title={Jack Audio Connection Kit},
	author={Paul Davis AND Stéphane Letz AND others},
	year={2002},
	howpublished={Open Source Project},
	note={\url{http://jackaudio.org/}}
}

@misc{Gstreamer,
	title={Gstreamer},
	author={Erik Walthinsen AND others},
	month={1},
	year={2001},
	howpublished={Open Source Project},
	note={\url{https://gstreamer.freedesktop.org/}}
}

@misc{rulebook_2018,
	author = {Matamoros, Mauricio AND Rascon, Caleb AND Hart, Justin AND Holz, Dirk AND van Beek, Loy },
	title = {RoboCup@Home 2018: Rules and Regulations},
	pages = {64 -- 67},
	year = {2018},
	howpublished = {\url{http://www.robocupathome.org/rules/2018_rulebook.pdf}},
}

@misc{psutil,
	title={psutil},
	author={Giampaolo Rodola AND others},
	year={2013},
	howpublished={Open Source Project},
	note={\url{https://psutil.readthedocs.io}}
}

@misc{ToBi,
	title={Team of Bielefeld},
	year={2009},
	howpublished={RoboCup@Home Participants},
	note={\url{https://www.cit-ec.de/en/tobi}}
}

@misc{GoogleSpeech,
	title={Google Cloud Speech-to-Text},
	author={Google},
	year={2013},
	month={11},
	day={6},
	howpublished={Software Product},
	note={\url{https://cloud.google.com/speech-to-text/}}
}

@misc{MicrosoftSpeech,
	title={Microsoft Speech to Text},
	author={Microsoft},
	year={2018},
	month={9},
	howpublished={Software Product},
	note={\url{https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/}}
}

@article{pyroomacoustics,
	author = {Robin Scheibler AND Eric Bezzam AND Ivan Dokmanić},
	title = {Pyroomacoustics: A Python package for audio room simulations and array processing algorithms},
	year = {2017},
	eprint = {arXiv:1710.04196},
	doi = {10.1109/ICASSP.2018.8461310},
}

@phdthesis{bonsai,
	type = {dissertation},
	title = {Behavior coordination for reusable system design in interactive robotics},
	author = {Siepmann Frederic},
	school = {Bielefeld University},
	year = {2013},
}

@article{deepspeech,
	author    = {Awni Y. Hannun and
	Carl Case and
	Jared Casper and
	Bryan Catanzaro and
	Greg Diamos and
	Erich Elsen and
	Ryan Prenger and
	Sanjeev Satheesh and
	Shubho Sengupta and
	Adam Coates and
	Andrew Y. Ng},
	title     = {Deep Speech: Scaling up end-to-end speech recognition},
	journal   = {CoRR},
	volume    = {abs/1412.5567},
	year      = {2014},
	url       = {http://arxiv.org/abs/1412.5567},
	archivePrefix = {arXiv},
	eprint    = {1412.5567},
	timestamp = {Mon, 13 Aug 2018 16:48:07 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/HannunCCCDEPSSCN14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{tensorflow,
	title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={http://tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
	Mart\'{i}n~Abadi and
	Ashish~Agarwal and
	Paul~Barham and
	Eugene~Brevdo and
	Zhifeng~Chen and
	Craig~Citro and
	Greg~S.~Corrado and
	Andy~Davis and
	Jeffrey~Dean and
	Matthieu~Devin and
	Sanjay~Ghemawat and
	Ian~Goodfellow and
	Andrew~Harp and
	Geoffrey~Irving and
	Michael~Isard and
	Yangqing Jia and
	Rafal~Jozefowicz and
	Lukasz~Kaiser and
	Manjunath~Kudlur and
	Josh~Levenberg and
	Dan~Man\'{e} and
	Rajat~Monga and
	Sherry~Moore and
	Derek~Murray and
	Chris~Olah and
	Mike~Schuster and
	Jonathon~Shlens and
	Benoit~Steiner and
	Ilya~Sutskever and
	Kunal~Talwar and
	Paul~Tucker and
	Vincent~Vanhoucke and
	Vijay~Vasudevan and
	Fernanda~Vi\'{e}gas and
	Oriol~Vinyals and
	Pete~Warden and
	Martin~Wattenberg and
	Martin~Wicke and
	Yuan~Yu and
	Xiaoqiang~Zheng},
	year={2015},
}

@article{Nakadai_2017jrm,
	title={Development, Deployment and Applications of Robot Audition Open Source Software HARK},
	author={Kazuhiro Nakadai and Hiroshi G. Okuno and Takeshi Mizumoto},
	journal={Journal of Robotics and Mechatronics},
	volume={29},
	number={1},
	pages={16-25},
	year={2017},
	doi={10.20965/jrm.2017.p0016},
}

@INPROCEEDINGS{287895,
	author={A. T. {Alouani} and T. R. {Rice}},
	booktitle={Proceedings of 26th Southeastern Symposium on System Theory},
	title={On asynchronous data fusion},
	year={1994},
	pages={143-146},
	keywords={sensor fusion;delays;tracking;asynchronous data fusion;multisensor tracking system;sequential processing;inherent delay;multitasking radar;dissimilar sensors;Biosensors;Sensor systems;Sensor fusion;Acoustic sensors;Optical sensors;Laser radar;Time measurement;Delay;Radar measurements;Humans},
	doi={10.1109/SSST.1994.287895},
	month={March},
}

@article{TURK2014189,
	title = {Multimodal interaction: A review},
	journal = {Pattern Recognition Letters},
	volume = {36},
	pages = {189 - 195},
	year = {2014},
	issn = {0167-8655},
	doi = {https://doi.org/10.1016/j.patrec.2013.07.003},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865513002584},
	author = {Matthew Turk},
	keywords = {Multimodal interaction, Perceptual interface, Multimodal integration, Review},
	abstract = {People naturally interact with the world multimodally, through both parallel and sequential use of multiple perceptual modalities. Multimodal human–computer interaction has sought for decades to endow computers with similar capabilities, in order to provide more natural, powerful, and compelling interactive experiences. With the rapid advance in non-desktop computing generated by powerful mobile devices and affordable sensors in recent years, multimodal research that leverages speech, touch, vision, and gesture is on the rise. This paper provides a brief and personal review of some of the key aspects and issues in multimodal interaction, touching on the history, opportunities, and challenges of the area, especially in the area of multimodal integration. We review the question of early vs. late integration and find inspiration in recent evidence in biological sensory integration. Finally, we list challenges that lie ahead for research in multimodal human–computer interaction.},
}

@article{PORIA201650,
	title = {Fusing audio, visual and textual clues for sentiment analysis from multimodal content},
	journal = {Neurocomputing},
	volume = {174},
	pages = {50 - 59},
	year = {2016},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/j.neucom.2015.01.095},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231215011297},
	author = {Soujanya Poria and Erik Cambria and Newton Howard and Guang-Bin Huang and Amir Hussain},
	keywords = {Multimodal fusion, Big social data analysis, Opinion mining, Multimodal sentiment analysis, Sentic computing},
	abstract = {A huge number of videos are posted every day on social media platforms such as Facebook and YouTube. This makes the Internet an unlimited source of information. In the coming decades, coping with such information and mining useful knowledge from it will be an increasingly difficult task. In this paper, we propose a novel methodology for multimodal sentiment analysis, which consists in harvesting sentiments from Web videos by demonstrating a model that uses audio, visual and textual modalities as sources of information. We used both feature- and decision-level fusion methods to merge affective information extracted from multiple modalities. A thorough comparison with existing works in this area is carried out throughout the paper, which demonstrates the novelty of our approach. Preliminary comparative experiments with the YouTube dataset show that the proposed multimodal system achieves an accuracy of nearly 80\%, outperforming all state-of-the-art systems by more than 20\%.},
}

@inproceedings{10.1117/12.138164,
	author = {W. Dale Blair and Theodore R. Rice and Brendan S. McDole and E. M. Sproul},
	title = {{Least-squares approach to asynchronous data fusion}},
	volume = {1697},
	booktitle = {Acquisition, Tracking, and Pointing VI},
	editor = {Michael K. Masten and Larry A. Stockum},
	organization = {International Society for Optics and Photonics},
	publisher = {SPIE},
	pages = {130 -- 141},
	year = {1992},
	doi = {10.1117/12.138164},
	URL = {https://doi.org/10.1117/12.138164}
}

@ARTICLE{4383603,
	author={L. P. {Yan} and B. S. {Liu} and D. H. {Zhou}},
	journal={IEEE Transactions on Aerospace and Electronic Systems},
	title={Asynchronous multirate multisensor information fusion algorithm},
	year={2007},
	volume={43},
	number={3},
	pages={1135-1146},
	keywords={recursive estimation;sensor fusion;state estimation;asynchronous multirate multisensor;optimal dynamic information fusion;state space models;state estimation;global measurements;linear minimum variance;State estimation;Signal processing algorithms;Sampling methods;Signal resolution;Sensor fusion;Recursive estimation;Stochastic processes;Image reconstruction;State-space methods},
	doi={10.1109/TAES.2007.4383603},
	month={July},
}

@ARTICLE{1468761,
	author={A. T. {Alouani} and J. E. {Gray} and D. H. {McCabe}},
	journal={IEEE Transactions on Aerospace and Electronic Systems},
	title={Theory of distributed estimation using multiple asynchronous sensors},
	year={2005},
	volume={41},
	number={2},
	pages={717-722},
	keywords={sensor fusion;target tracking;synchronisation;distributed estimation;multiple asynchronous sensors;track fusion;linear fusion rule;batch processing;Bar-Shalom-Campo fusion rule;Estimation theory;Sensor fusion;State estimation;Computer architecture;Delay estimation;Computational efficiency;Gaussian processes;Gaussian noise;Time measurement;Delay effects},
	doi={10.1109/TAES.2005.1468761},
	month={April},
}