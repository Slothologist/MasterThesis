%!TEX root = thesis.tex

\chapter{Related Work}

In this chapter a number of frameworks and libraries for audio transmission and their merit for speech recognition will be discussed.

\section{ALSA/ PulseAudio}
The Advanced Linux Sound Architecture (ALSA) 

\begin{itemize}
	\item 
\end{itemize}

%-------------------------------------------------------------------------------------
\section{JACK Audio}

The Jack audio connection kit (JACK) is a protocol for audio transmission between components with the explicit requirement for a low latency, to enable real time capture, playback and editing of sound. 
It provides an API to transmit audio between programs. 

Several implementations of JACK servers exist, notably JACK1 and JACK2. 
Differences between implementations are quite small and boil down to a handful of optional features and support for some operating systems which will most likely not matter for most users. % see https://github.com/jackaudio/jackaudio.github.com/wiki/Q_difference_jack1_jack2
Since all implementations provide the same interfaces, components are indifferent to the implementation of the JACK server used. 

JACK requires components to use a specific sample rate, sample size and audio format, which can however be adjusted before starting the JACK server. 
As such, any component which requires a different audio format has to handle resampling and converting on its own. 

JACK does not allow for additional information to transmitted with the raw audio it transports, so any additionally information must be transmitted and synchronized separately with another middleware. 

JACK is able to transmit audio over network, but generally requires all participating computers to run an instance of the same server implementation. 
An additional piece of software is needed to then create the connection between the different server instances. 
This complexity results in a moderate amount of setup and maintenance time required to handle an ever changing setup of computers and components a robot, especially in a research context, requires.

JACK requires all components which use its API to process audio in a specific and rather short time. 
Audio is written to and read from JACK via buffers, which will be in turn read and written by JACK in specific intervals.
If a component is not able to read or produce audio fast enough, JACK will overwrite or read old audio respectively, so audio is lost. 
This is important for applications which result in humans hearing the transmitted audio directly, to reduce latency and negate long or at least noticeable periods of silence.

\subsection{Problems regarding distributed Speech recognition applications}
For speech recognition purposes however, this audio frame dropping produces a series of problems. 
For once, transitions between audio frames become non-steady, which results in artifacts when frequency analysis or other feature extraction is employed.
Feature extraction algorithms using deep learning for example may not have been trained with audio which misses frames, and produce incomprehensible or unexpected results.


%-------------------------------------------------------------------------------------
\section{Gstreamer}

\begin{itemize}
	\item 
\end{itemize}

%-------------------------------------------------------------------------------------

\section{Interoperability between presented Frameworks}
\begin{itemize}
	\item most if not all of these frameworks can be used alongside each other and often have interfaces to each other
	\item 
\end{itemize}


